{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from uuid import uuid4\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_BASE_URL\"] = 'https://api.bianxie.ai/v1'\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'sk-FEDzYSgWNKkHgc7labPUIfiFPpI3RZ1Wd7lR6fg2yZ1nNefP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    max_tokens=1024,\n",
    "    temperature = 0.7,\n",
    "    top_p = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pickle(obj, filename):\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(obj, file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_from_pickle(filename):\n",
    "    with open(filename, \"rb\") as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docstore.pkl\", \"rb\") as file:\n",
    "    store_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docstore.pkl\", \"rb\") as file:   \n",
    "    store_dict = pickle.load(file)\n",
    "persist_directory = \"./parentDB\"\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"product\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "store = InMemoryStore()\n",
    "store.mset(list(store_dict.items()))\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=600)\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vector_store,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    search_kwargs={\"k\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vector_store.get()['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a chain for chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\"\"\"You are a Q&A agent that assists customers with inquiries. Your main objectives are to provide accurate information, address customer concerns, and enhance the shopping experience.\\\n",
    "                             In your response, please strictly follow the following instructions: \n",
    "                             1. Always remember previous interactions in the conversation history. Use this information to inform your responses and provide relevant answers.\\\n",
    "                             2. If you do not know the answer to a question, say that you don't know.\\\n",
    "                             3. Assess the content of the retrieved documents to determine their usefulness in answering the user's question. Not all documents will be relevant.\\\n",
    "                             3. Base your answers on your own knowledge and supplement your answers with information from relevant documents. \\\n",
    "                             4. DO NOT specifically mention the retrieved documents and provided information in your response.\\\n",
    "                             Retrieved Documents:\n",
    "                             {context}\"\"\"\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "context1 = itemgetter(\"question\") | retriever | format_docs\n",
    "context2 = itemgetter(\"question\") | retriever \n",
    "first_step1 = RunnablePassthrough.assign(context=context1)\n",
    "first_step2 = RunnablePassthrough.assign(context=context2)\n",
    "prompt1 = first_step1 | qa_prompt\n",
    "prompt2 = first_step2 | qa_prompt\n",
    "rag_chain = first_step2 | qa_prompt | chat_model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Any recommendation for cameras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "def get_session_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "        if session_id not in store:\n",
    "            store[session_id] = InMemoryChatMessageHistory()\n",
    "        return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key = 'question',\n",
    "    history_messages_key = \"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history.invoke(\n",
    "        {\"question\": \"Hi, I'm Joe. Can you help me on finding the right products?\"},\n",
    "        config={\"configurable\": {\"session_id\": \"1\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history.invoke(\n",
    "        {\"question\": \"If I want to purchase a camera. Which aspect of camera should I focus on?\"},\n",
    "        config={\"configurable\": {\"session_id\": \"1\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history.invoke(\n",
    "        {\"question\": \"What's my name?\"},\n",
    "        config={\"configurable\": {\"session_id\": \"1\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store['1'].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_conversation(conversation_history, filename):\n",
    "\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(conversation_history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversation(filename):\n",
    "\n",
    "    try:\n",
    "        with open(filename, 'rb') as file:\n",
    "            conversation_history = pickle.load(file)\n",
    "        return conversation_history\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {filename} not found.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading conversation history: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_conversation(store[\"1\"].messages, \"test_history.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_conversation(\"test_history.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chrenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
